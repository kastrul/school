{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\janvi\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "import gensim  #for topic modelling\n",
    "import nltk  # for text preprocessing\n",
    "import pandas as pd  #for io\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, \\\n",
    "    remove_stopwords, stem_text\n",
    "from ipywidgets import fixed, interact_manual\n",
    "\n",
    "logging.basicConfig(format='\\r%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    return [f for f in listdir(path) if isfile(join(path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = 'iso-8859-1'\n",
    "PATH_ANSWERS = '../data/stacksample/Answers.csv'\n",
    "pp = pprint.PrettyPrinter(indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_QUESTIONS = '../data/stacksample/Questions.csv'\n",
    "COLUMNS_QUESTION = ['Title', 'Body']\n",
    "N_ROWS = 10\n",
    "\n",
    "question_df = pd.read_csv(PATH_QUESTIONS, encoding=ENCODING, nrows=N_ROWS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of     Id  OwnerUserId          CreationDate            ClosedDate  Score  \\\n",
       "0   80           26  2008-08-01T13:57:07Z                   NaN     26   \n",
       "1   90           58  2008-08-01T14:41:24Z  2012-12-26T03:45:49Z    144   \n",
       "2  120           83  2008-08-01T15:50:08Z                   NaN     21   \n",
       "3  180      2089740  2008-08-01T18:42:19Z                   NaN     53   \n",
       "4  260           91  2008-08-01T23:22:08Z                   NaN     49   \n",
       "5  330           63  2008-08-02T02:51:36Z                   NaN     29   \n",
       "6  470           71  2008-08-02T15:11:47Z  2016-03-26T05:23:29Z     13   \n",
       "7  580           91  2008-08-02T23:30:59Z                   NaN     21   \n",
       "8  650          143  2008-08-03T11:12:52Z                   NaN     79   \n",
       "9  810          233  2008-08-03T20:35:01Z                   NaN      9   \n",
       "\n",
       "                                               Title  \\\n",
       "0  SQLStatement.execute() - multiple queries in o...   \n",
       "1  Good branching and merging tutorials for Torto...   \n",
       "2                                  ASP.NET Site Maps   \n",
       "3                 Function for creating color wheels   \n",
       "4  Adding scripting functionality to .NET applica...   \n",
       "5          Should I use nested classes in this case?   \n",
       "6              Homegrown consumption of web services   \n",
       "7   Deploying SQL Server Databases from Test to Live   \n",
       "8                Automatically update version number   \n",
       "9  Visual Studio Setup Project - Per User Registr...   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>I've written a database generation script i...  \n",
       "1  <p>Are there any really good tutorials explain...  \n",
       "2  <p>Has anyone got experience creating <strong>...  \n",
       "3  <p>This is something I've pseudo-solved many t...  \n",
       "4  <p>I have a little game written in C#. It uses...  \n",
       "5  <p>I am working on a collection of classes use...  \n",
       "6  <p>I've been writing a few web services for a ...  \n",
       "7  <p>I wonder how you guys manage deployment of ...  \n",
       "8  <p>I would like the version property of my app...  \n",
       "9  <p>I'm trying to maintain a Setup Project in <...  >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df['All'] = question_df['Title'].map(str) + question_df['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TAGS = '../data/stacksample/Tags.csv'\n",
    "tags_df = pd.read_csv(PATH_TAGS, encoding=ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_state(current, target, loading=True):\n",
    "    if loading:\n",
    "        state = round((current / target) * 100.0, 2)\n",
    "        print('\\rLoading: ' + str(state) + '%', end='')\n",
    "    else:\n",
    "        print(f'\\rRow {current}/{target}', end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "ALLOWED_SHORT_WORDS = ['c', 'c#', 'r', '3d', '2d', '1d', '7z', 'qt']\n",
    "\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    return re.sub(\"(\\<.*?\\>)\", \"\", text)\n",
    "\n",
    "\n",
    "def filter_text(tokenized_text):\n",
    "    return [stemmer.stem(word) for word in tokenized_text if stemmer.stem(word) not in stop_words]\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return filter_text(gensim.utils.simple_preprocess(str(remove_html_tags(text)), deacc=True))\n",
    "\n",
    "\n",
    "def strip_short(word_list):    \n",
    "    return [str(word).lower() for word in word_list if len(word) > 2 or word in ALLOWED_SHORT_WORDS]\n",
    "\n",
    "\n",
    "def prepare_document(document, e_filters=[], show_state=True, show_idx=1):\n",
    "    output = []\n",
    "    doc_length = len(document)\n",
    "    for idx, text in enumerate(document):\n",
    "        if show_state and idx % show_idx == 0:\n",
    "            print_state(idx + 1, doc_length)\n",
    "        output.append(simple_tokenize_text(text, extra_filters=e_filters))\n",
    "    return output\n",
    "\n",
    "\n",
    "def simple_tokenize_text(text, extra_filters=[], remove_short=True):\n",
    "    text_filters=[strip_tags, strip_punctuation, strip_multiple_whitespaces, remove_stopwords]\n",
    "    if (len(extra_filters) > 0): \n",
    "        text_filters = text_filters + extra_filers\n",
    "    p = preprocess_string(text, filters=text_filters)\n",
    "    if (remove_short):\n",
    "        return strip_short(p)\n",
    "    else:\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS = 1000\n",
    "q_titles = question_df['Title'][:]\n",
    "q_texts = question_df['All'][:]\n",
    "#q_tags = tags_df['Tag'][:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_tokens(corpus, file_name='', save_data=False):\n",
    "    q_texts_tokenized = prepare_document(corpus, show_idx=1000)\n",
    "    if save_data:\n",
    "        with open(f'../data/stacksample/tokenized/{file_name}.json', 'w', encoding=ENCODING) as f:\n",
    "            print('Saving data...')\n",
    "            json.dump(q_texts_tokenized, f)\n",
    "            print(f'Data saved as {file_name}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edab361849754a4681cd343fe96224d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_texts_tokenized = interact_manual(corpus_to_tokens, corpus=fixed(q_texts), file_name='new_file_name', save_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.StreamHandler.terminator = ''\n",
    "def build_dictionary(file_name, save_dict_name='', save_data=False):\n",
    "    with open(f'../data/stacksample/tokenized/{file_name}') as f:\n",
    "        print('Waiting for data...')\n",
    "        tokenized_corpus = json.load(f)\n",
    "        dict_texts = gensim.corpora.Dictionary(tokenized_corpus)\n",
    "        if save_data:\n",
    "            print('Saving data...')\n",
    "            dict_texts.save(f'../data/stacksample/dictionary/{save_dict_name}.dict')\n",
    "    return dict_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22865ebc77be4cc4a214676a199bff57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.build_dictionary>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(build_dictionary, file_name=get_files('../data/stacksample/tokenized'), \n",
    "                save_dict_name='new_file_name', save_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Bag of words* creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.StreamHandler.terminator = ''\n",
    "def build_bow(tokenized_file, dictionary_file, save_file='', save_data=False):\n",
    "    corpus_dictionary = gensim.corpora.Dictionary.load(f'../data/stacksample/dictionary/{dictionary_file}')\n",
    "    with open(f'../data/stacksample/tokenized/{tokenized_file}') as f:\n",
    "        tokenized_corpus = json.load(f)\n",
    "    corpus_bow = [corpus_dictionary.doc2bow(text) for text in tokenized_corpus]\n",
    "    if save_data:\n",
    "        gensim.corpora.MmCorpus.serialize(f'../data/stacksample/bow/{save_file}.mm', corpus_bow)\n",
    "    return corpus_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3857ae4d29645b087f401fb385925f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.build_bow>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(build_bow, tokenized_file=get_files('../data/stacksample/tokenized'), \n",
    "                dictionary_file=get_files('../data/stacksample/dictionary'), save_file='new_file_name', save_data=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-03 17:26:54,048 : INFO : loading Dictionary object from ../data/stacksample/dictionary/question_title_body.dict\n",
      "2018-06-03 17:26:55,261 : INFO : loaded ../data/stacksample/dictionary/question_title_body.dict\n"
     ]
    }
   ],
   "source": [
    "from six import iteritems\n",
    "\n",
    "DICT_NAME = 'question_title_body.dict'\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary.load(f'../data/stacksample/dictionary/{DICT_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_tokens(once_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-03 17:28:35,864 : INFO : saving Dictionary object under ../data/stacksample/dictionary/question_title_body_compact.dict, separately None\n",
      "2018-06-03 17:28:36,208 : INFO : saved ../data/stacksample/dictionary/question_title_body_compact.dict\n"
     ]
    }
   ],
   "source": [
    "dictionary.save('../data/stacksample/dictionary/question_title_body_compact.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_question(index):\n",
    "    tokenized_text = preprocess_string(question_df['Title'][index])\n",
    "    return dict_texts.doc2bow(tokenized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (0, '0.024*\"build\" + 0.021*\"file\"'),\n",
      "    (1, '0.017*\"code\" + 0.012*\"string\"'),\n",
      "    (2, '0.010*\"us\" + 0.009*\"user\"'),\n",
      "    (3, '0.052*\"script\" + 0.032*\"http\"'),\n",
      "    (4, '0.020*\"tabl\" + 0.011*\"file\"'),\n",
      "    (5, '0.018*\"server\" + 0.011*\"applic\"'),\n",
      "    (6, '0.019*\"class\" + 0.014*\"public\"'),\n",
      "    (7, '0.014*\"data\" + 0.013*\"object\"'),\n",
      "    (8, '0.020*\"text\" + 0.012*\"string\"'),\n",
      "    (9, '0.015*\"page\" + 0.012*\"applic\"')]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(ldamodel.print_topics(num_topics=10, num_words=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (0, 0.020003743),\n",
      "    (1, 0.02000364),\n",
      "    (2, 0.8199628),\n",
      "    (3, 0.020003308),\n",
      "    (4, 0.02000456),\n",
      "    (5, 0.02000247),\n",
      "    (6, 0.02000974),\n",
      "    (7, 0.02000231),\n",
      "    (8, 0.02000356),\n",
      "    (9, 0.020003838)]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(ldamodel[get_bow_question(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
