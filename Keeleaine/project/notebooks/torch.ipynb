{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import MmCorpus, Dictionary\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(format='\\r%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = 'iso-8859-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TAGS = '../data/stacksample/Tags.csv'\n",
    "tags_df = pd.read_csv(PATH_TAGS, encoding=ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-04 19:45:11,513 : INFO : loading Dictionary object from ../data/stacksample/dictionary/titles_body_compact.dict\n",
      "2018-06-04 19:45:12,845 : INFO : loaded ../data/stacksample/dictionary/titles_body_compact.dict\n",
      "2018-06-04 19:45:13,110 : INFO : loaded corpus index from ../data/stacksample/bow/titles_body_compact.mm.index\n",
      "2018-06-04 19:45:13,112 : INFO : initializing cython corpus reader from ../data/stacksample/bow/titles_body_compact.mm\n",
      "2018-06-04 19:45:13,181 : INFO : accepted corpus with 1264216 documents, 2009852 features, 65879940 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "DICT_F = 'titles_body_compact.dict'\n",
    "BOW_F = 'titles_body_compact.mm'\n",
    "\n",
    "corpus_dict = Dictionary.load(f'../data/stacksample/dictionary/{DICT_F}')\n",
    "corpus_bow = MmCorpus(f'../data/stacksample/bow/{BOW_F}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(13, 6.0), (32, 1.0), (40, 1.0), (42, 1.0), (43, 1.0), (57, 5.0), (59, 3.0), (69, 3.0), (80, 2.0), (110, 2.0), (118, 2.0), (135, 1.0), (161, 2.0), (181, 2.0), (232, 1.0), (236, 1.0), (281, 1.0), (288, 1.0), (289, 1.0), (329, 1.0), (393, 1.0), (476, 2.0), (535, 1.0), (634, 1.0), (914, 1.0), (1063, 1.0), (1256, 1.0), (1868, 1.0), (2819, 2.0), (3456, 2.0)]\n"
     ]
    }
   ],
   "source": [
    "def create_data():\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['facebook'\", \"'bookmarklet'\", \"'fbml'\", \"'fbjs']\"]\n"
     ]
    }
   ],
   "source": [
    "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is vocab_size\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, max_size=10000)\n",
    "TAGS.build_vocab(train_data, max_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits((train_data, test_data), batch_size=32, device=-1, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,   925,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,  2158,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.text)\n",
    "print(batch.tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
